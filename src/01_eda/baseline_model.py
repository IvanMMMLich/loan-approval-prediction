"""
===============================================================================
                    üí≥ BASELINE MODEL
                    
                 –ü–µ—Ä–≤–∞—è –º–æ–¥–µ–ª—å –ë–ï–ó –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
                        "Quick and Dirty"
===============================================================================

–¶–ï–õ–¨:
-----
–°–æ–∑–¥–∞—Ç—å –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å –Ω–∞ –°–´–†–´–• –¥–∞–Ω–Ω—ã—Ö —á—Ç–æ–±—ã –ø–æ—Ç–æ–º —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å
–Ω–∞—Å–∫–æ–ª—å–∫–æ –∫–∞–∂–¥—ã–π —à–∞–≥ –∞–Ω–∞–ª–∏–∑–∞ —É–ª—É—á—à–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.

–ß–¢–û –î–ï–õ–ê–ï–ú:
----------
1. –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (—Ç–æ–ª—å–∫–æ —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –∑–∞–ø—É—Å—Ç–∏–ª–∞—Å—å)
2. –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è
3. –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
"""

import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import (
    roc_auc_score, 
    classification_report,
    confusion_matrix,
    roc_curve
)
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
from datetime import datetime

# –ü—É—Ç–∏ 
import os
from pathlib import Path

# –ò—â–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –ø–æ –Ω–∞–ª–∏—á–∏—é –ø–∞–ø–∫–∏ data
current = Path(__file__).parent
while current != current.parent:
    if (current / 'data' / 'raw').exists():
        ROOT_DIR = current
        break
    current = current.parent
    
DATA_RAW = ROOT_DIR / 'data' / 'raw'
RESULTS = ROOT_DIR / 'results' / 'model_versions' / 'v0_baseline'
RESULTS.mkdir(parents=True, exist_ok=True) 

def create_baseline_model():
    """–°–æ–∑–¥–∞–µ–º baseline –º–æ–¥–µ–ª—å –Ω–∞ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
    
    print("="*60)
    print("BASELINE MODEL - v0")
    print("–ú–æ–¥–µ–ª—å –Ω–∞ –°–´–†–´–• –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    print("="*60)
    
    # ========== 1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ==========
    train_df = pd.read_csv(DATA_RAW / 'train.csv')
    print(f"\nüìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(train_df)} –∑–∞–ø–∏—Å–µ–π")
    
    # ========== 2. –ú–ò–ù–ò–ú–ê–õ–¨–ù–ê–Ø –ü–û–î–ì–û–¢–û–í–ö–ê ==========
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ X –∏ y
    X = train_df.drop(['id', 'loan_status'], axis=1)
    y = train_df['loan_status']
    
    # –ö–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ (–∏–Ω–∞—á–µ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–ø—É—Å—Ç–∏—Ç—Å—è)
    print("\nüîß –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö...")
    
    le_dict = {}
    categorical_cols = X.select_dtypes(include=['object']).columns
    
    for col in categorical_cols:
        le = LabelEncoder()
        X[col] = le.fit_transform(X[col])
        le_dict[col] = le
        print(f"   ‚Ä¢ {col}: {len(le.classes_)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
    
    # –ù–ï –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—ã–±—Ä–æ—Å—ã (123 –≥–æ–¥–∞)
    # –ù–ï –¥–µ–ª–∞–µ–º feature engineering
    # –ù–ï –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º
    print("\n‚ö†Ô∏è –ë–ï–ó –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
    print("   ‚Ä¢ –û—Å—Ç–∞–≤–ª—è–µ–º 123 –≤ –≤–æ–∑—Ä–∞—Å—Ç–µ –∏ —Å—Ç–∞–∂–µ")
    print("   ‚Ä¢ –ù–µ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏")
    print("   ‚Ä¢ –ù–µ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏")
    
    # ========== 3. –†–ê–ó–î–ï–õ–ï–ù–ò–ï –ù–ê TRAIN/VAL ==========
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"\nüìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ:")
    print(f"   Train: {len(X_train)} ({y_train.mean():.1%} positive)")
    print(f"   Val: {len(X_val)} ({y_val.mean():.1%} positive)")
    
    # ========== 4. –û–ë–£–ß–ï–ù–ò–ï BASELINE ==========
    print("\nüöÄ –û–±—É—á–∞–µ–º Logistic Regression...")
    
    model = LogisticRegression(
        class_weight='balanced',  # –ò–∑-–∑–∞ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞
        max_iter=1000,
        random_state=42
    )
    
    model.fit(X_train, y_train)
    print("‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞!")
    
    # ========== 5. –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø ==========
    y_pred_proba = model.predict_proba(X_val)[:, 1]
    y_pred = model.predict(X_val)
    
    # ========== 6. –ú–ï–¢–†–ò–ö–ò ==========
    print("\nüìà –ú–ï–¢–†–ò–ö–ò BASELINE:")
    print("-"*40)
    
    # ROC-AUC
    roc_auc = roc_auc_score(y_val, y_pred_proba)
    print(f"ROC-AUC: {roc_auc:.4f}")
    
    # Classification Report
    report = classification_report(y_val, y_pred, 
                                  target_names=['Rejected', 'Approved'])
    print("\nClassification Report:")
    print(report)
    
    # Confusion Matrix
    cm = confusion_matrix(y_val, y_pred)
    print("\nConfusion Matrix:")
    print(f"TN: {cm[0,0]:5d}  FP: {cm[0,1]:5d}")
    print(f"FN: {cm[1,0]:5d}  TP: {cm[1,1]:5d}")
    
    # ========== 7. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ==========
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ —Ñ–∞–π–ª
    with open(RESULTS / 'metrics.txt', 'w') as f:
        f.write("BASELINE MODEL METRICS\n")
        f.write("="*50 + "\n")
        f.write(f"Date: {datetime.now()}\n")
        f.write(f"Model: LogisticRegression\n")
        f.write(f"Features: {X.shape[1]}\n")
        f.write(f"Train size: {len(X_train)}\n")
        f.write(f"Val size: {len(X_val)}\n")
        f.write("\nPERFORMANCE:\n")
        f.write(f"ROC-AUC: {roc_auc:.4f}\n")
        f.write("\n" + report)
        f.write("\nCONFUSION MATRIX:\n")
        f.write(f"TN: {cm[0,0]:5d}  FP: {cm[0,1]:5d}\n")
        f.write(f"FN: {cm[1,0]:5d}  TP: {cm[1,1]:5d}\n")
        f.write("\nNOTES:\n")
        f.write("- No data cleaning (123 values kept)\n")
        f.write("- No feature engineering\n")
        f.write("- No scaling\n")
        f.write("- Only label encoding for categorical\n")
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è Confusion Matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Rejected', 'Approved'],
                yticklabels=['Rejected', 'Approved'])
    plt.title('Confusion Matrix - Baseline Model')
    plt.ylabel('True')
    plt.xlabel('Predicted')
    plt.savefig(RESULTS / 'confusion_matrix.png')
    plt.close()
    
    # ROC Curve
    fpr, tpr, _ = roc_curve(y_val, y_pred_proba)
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, label=f'ROC (AUC = {roc_auc:.3f})')
    plt.plot([0, 1], [0, 1], 'k--', label='Random')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve - Baseline Model')
    plt.legend()
    plt.grid(alpha=0.3)
    plt.savefig(RESULTS / 'roc_curve.png')
    plt.close()
    
    # Feature Importance
    importance = pd.DataFrame({
        'feature': X.columns,
        'coefficient': model.coef_[0],
        'abs_coefficient': np.abs(model.coef_[0])
    }).sort_values('abs_coefficient', ascending=False)
    
    importance.to_csv(RESULTS / 'feature_importance.csv', index=False)
    
    # –¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    plt.figure(figsize=(10, 6))
    top10 = importance.head(10)
    plt.barh(range(10), top10['coefficient'].values)
    plt.yticks(range(10), top10['feature'].values)
    plt.xlabel('Coefficient')
    plt.title('Top 10 Features - Baseline Model')
    plt.grid(alpha=0.3)
    plt.savefig(RESULTS / 'top_features.png')
    plt.close()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    with open(RESULTS / 'model.pkl', 'wb') as f:
        pickle.dump(model, f)
    
    with open(RESULTS / 'label_encoders.pkl', 'wb') as f:
        pickle.dump(le_dict, f)
    
    print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {RESULTS}")
    
    # ========== 8. SUMMARY ==========
    print("\n" + "="*60)
    print("BASELINE SUMMARY:")
    print("="*60)
    print(f"ROC-AUC: {roc_auc:.4f}")
    print(f"Precision (Approved): {cm[1,1]/(cm[1,1]+cm[0,1]):.3f}")
    print(f"Recall (Approved): {cm[1,1]/(cm[1,1]+cm[1,0]):.3f}")
    print("\nüí° –≠—Ç–æ –Ω–∞—à–∞ –æ—Ç–ø—Ä–∞–≤–Ω–∞—è —Ç–æ—á–∫–∞!")
    print("   –ö–∞–∂–¥—ã–π —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥ –¥–æ–ª–∂–µ–Ω —É–ª—É—á—à–∏—Ç—å —ç—Ç–∏ –º–µ—Ç—Ä–∏–∫–∏.")
    
    return model, roc_auc

if __name__ == "__main__":
    model, baseline_auc = create_baseline_model()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º baseline –º–µ—Ç—Ä–∏–∫—É –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    with open(RESULTS.parent / 'baseline_auc.txt', 'w') as f:
        f.write(f"{baseline_auc:.4f}")
